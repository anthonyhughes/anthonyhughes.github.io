{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetuning-bert-bilstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hhpWRFbguWsxYK6iNKiVtFGKnYJjk1Y2",
      "authorship_tag": "ABX9TyNsFejHNzJfwFL9Lsmms3fH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anthonyhughes/anthonyhughes.github.io/blob/master/finetuning_bert_bilstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "\n",
        "Fetch all necessary code and resources"
      ],
      "metadata": {
        "id": "8mlSO6fDAShQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQxxVc_U97fS",
        "outputId": "99ea9b7e-c21b-4532-e8d7-d98eb572dc43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "## Apply your own file structure here\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Check local directory\n",
        "!ls drive/MyDrive/ML4NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTs8duOpA86e",
        "outputId": "3fe12b94-8800-4d32-f8f8-3697748c1785"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " assignment_1_ml4nlp_anthony_hughes.gdoc\n",
            "'assignment_1_ml4nlp_knn_nb.ipynb - Colaboratory.pdf'\n",
            " assignment_2_ml4nlp_anthony_hughes.gdoc\n",
            " assignment_3_ml4nlp_anthony_hughes.gdoc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Switch to dedicated folder\n",
        "%cd drive/MyDrive/ML4NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6omFtGMBMX0",
        "outputId": "ea63b388-0983-4e45-bccb-eaab10d5b45a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML4NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Fetch all code\n",
        "!git clone https://github.com/anthonyhughes/finetuning-en-punctuation-restoration.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB36eQYIBMdR",
        "outputId": "81c946b7-e8c6-44ef-d23a-2920b8f2cf0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'finetuning-en-punctuation-restoration'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 26 (delta 2), reused 26 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Switch to new repo folder\n",
        "%cd /content/drive/MyDrive/ML4NLP/finetuning-en-punctuation-restoration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwcZwYjEBuG-",
        "outputId": "d1b548ac-ba95-4e4b-95d5-9d25d28bb1da"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML4NLP/finetuning-en-punctuation-restoration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Install all libraries\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1DavUWoBdT7",
        "outputId": "5972df0e-3c96-46e1-98fb-ff2195359841"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.17.0\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 7.8 MB/s \n",
            "\u001b[?25hCollecting torch==1.11.0\n",
            "  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 750.6 MB 11 kB/s \n",
            "\u001b[?25hCollecting tqdm==4.63.1\n",
            "  Downloading tqdm-4.63.1-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 47.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->-r requirements.txt (line 1)) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 51.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->-r requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->-r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0->-r requirements.txt (line 1)) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->-r requirements.txt (line 2)) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.17.0->-r requirements.txt (line 1)) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.17.0->-r requirements.txt (line 1)) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0->-r requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0->-r requirements.txt (line 1)) (7.1.2)\n",
            "Installing collected packages: tqdm, pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, torch\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.63.0\n",
            "    Uninstalling tqdm-4.63.0:\n",
            "      Successfully uninstalled tqdm-4.63.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 torch-1.11.0 tqdm-4.63.1 transformers-4.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "O_EUm9FaCREh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash src/run-train.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UU9xBSBCVwG",
        "outputId": "c8a7654c-aabd-4b76-8564-ddca79b19ffc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Starting the train!\n",
            "train: 100% 1129/1129 [05:04<00:00,  3.71it/s]\n",
            "epoch: 0, Train loss: 0.3158168380665927, Train accuracy: 0.8839040815168387\n",
            "eval: 100% 160/160 [00:13<00:00, 11.61it/s]\n",
            "epoch: 0, Val loss: 0.20033551659435034, Val accuracy: 0.9146724047781845\n",
            "train: 100% 1129/1129 [05:04<00:00,  3.71it/s]\n",
            "epoch: 1, Train loss: 0.21557015092157494, Train accuracy: 0.9106050607514179\n",
            "eval: 100% 160/160 [00:13<00:00, 11.63it/s]\n",
            "epoch: 1, Val loss: 0.16359261288307608, Val accuracy: 0.9317727815093378\n",
            "train: 100% 1129/1129 [05:04<00:00,  3.71it/s]\n",
            "epoch: 2, Train loss: 0.19203712337834314, Train accuracy: 0.919599805791243\n",
            "eval: 100% 160/160 [00:13<00:00, 11.64it/s]\n",
            "epoch: 2, Val loss: 0.15077714463695885, Val accuracy: 0.9377622705760903\n",
            "train: 100% 1129/1129 [05:03<00:00,  3.71it/s]\n",
            "epoch: 3, Train loss: 0.18221815970484612, Train accuracy: 0.9235762215144868\n",
            "eval: 100% 160/160 [00:13<00:00, 11.64it/s]\n",
            "epoch: 3, Val loss: 0.14421215816400945, Val accuracy: 0.9401285712370456\n",
            "train: 100% 1129/1129 [05:03<00:00,  3.72it/s]\n",
            "epoch: 4, Train loss: 0.17594011200540777, Train accuracy: 0.9263649238935805\n",
            "eval: 100% 160/160 [00:13<00:00, 11.67it/s]\n",
            "epoch: 4, Val loss: 0.13907937807962298, Val accuracy: 0.9422904181581735\n",
            "train: 100% 1129/1129 [05:03<00:00,  3.72it/s]\n",
            "epoch: 5, Train loss: 0.1705279225488486, Train accuracy: 0.9282759122317856\n",
            "eval: 100% 160/160 [00:13<00:00, 11.68it/s]\n",
            "epoch: 5, Val loss: 0.1361359170638025, Val accuracy: 0.9434165895775517\n",
            "train: 100% 1129/1129 [05:03<00:00,  3.72it/s]\n",
            "epoch: 6, Train loss: 0.1663883464646825, Train accuracy: 0.9300146232452349\n",
            "eval: 100% 160/160 [00:13<00:00, 11.64it/s]\n",
            "epoch: 6, Val loss: 0.1337764747440815, Val accuracy: 0.9442545147407795\n",
            "train: 100% 1129/1129 [05:03<00:00,  3.72it/s]\n",
            "epoch: 7, Train loss: 0.16279404975995224, Train accuracy: 0.9314203046994955\n",
            "eval: 100% 160/160 [00:13<00:00, 11.67it/s]\n",
            "epoch: 7, Val loss: 0.1327213881071657, Val accuracy: 0.9449282065720146\n",
            "train: 100% 1129/1129 [05:03<00:00,  3.72it/s]\n",
            "epoch: 8, Train loss: 0.15984652328005505, Train accuracy: 0.9326911836112602\n",
            "eval: 100% 160/160 [00:13<00:00, 11.65it/s]\n",
            "epoch: 8, Val loss: 0.13150456505827607, Val accuracy: 0.9452365630320825\n",
            "train: 100% 1129/1129 [05:03<00:00,  3.72it/s]\n",
            "epoch: 9, Train loss: 0.15710549094145862, Train accuracy: 0.9336560364464692\n",
            "eval: 100% 160/160 [00:13<00:00, 11.65it/s]\n",
            "epoch: 9, Val loss: 0.1309956130106002, Val accuracy: 0.9455214575875799\n",
            "Best validation Acc: 0.9455214575875799\n",
            "src/train.py:104: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  tp = np.zeros(1+len(punctuation_dict), dtype=np.int)\n",
            "src/train.py:105: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  fp = np.zeros(1+len(punctuation_dict), dtype=np.int)\n",
            "src/train.py:106: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  fn = np.zeros(1+len(punctuation_dict), dtype=np.int)\n",
            "src/train.py:107: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  cm = np.zeros((len(punctuation_dict), len(punctuation_dict)), dtype=np.int)\n",
            "test: 100% 160/160 [00:45<00:00,  3.49it/s]\n",
            "Precision: [0.97537612 0.72636177 0.78564451 0.72543742 0.75487065]\n",
            "Recall: [0.98485584 0.62959334 0.80803808 0.71061305 0.71115724]\n",
            "F1 score: [0.98009306 0.67452459 0.79668396 0.71794872 0.73236223]\n",
            "Accuracy:0.9455214575875799\n",
            "Confusion Matrix[[251609   2816    925    128]\n",
            " [  5082  14135   3078    156]\n",
            " [  1147   2359  15280    124]\n",
            " [   123    150    166   1078]]\n",
            "\n",
            "test: 100% 7/7 [00:01<00:00,  3.53it/s]\n",
            "Precision: [0.98231207 0.70860077 0.80830281 0.74545455 0.75922565]\n",
            "Recall: [0.98497873 0.66506024 0.82032218 0.89130435 0.74569222]\n",
            "F1 score: [0.98364359 0.68614046 0.81426814 0.81188119 0.75239808]\n",
            "Accuracy:0.9533532275797079\n",
            "Confusion Matrix[[10885   134    30     2]\n",
            " [  147   552   126     5]\n",
            " [   49    89   662     7]\n",
            " [    0     4     1    41]]\n",
            "\n",
            "test: 100% 7/7 [00:02<00:00,  3.44it/s]\n",
            "Precision: [0.97597356 0.58041112 0.74069767 0.53191489 0.65859285]\n",
            "Recall: [0.96801914 0.60150376 0.78739184 0.71428571 0.6954933 ]\n",
            "F1 score: [0.97198007 0.59076923 0.76333134 0.6097561  0.67654028]\n",
            "Accuracy:0.9334106728538283\n",
            "Confusion Matrix[[10927   272    81     8]\n",
            " [  180   480   136     2]\n",
            " [   85    75   637    12]\n",
            " [    4     0     6    25]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "dhXXTDrQFJH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull\n",
        "!bash src/run-inference.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLLatgWaFzdq",
        "outputId": "ef8589c3-d7bf-4e38-d8ad-351e88b7f765"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Punctuated text\n",
            "In mathematics, particularly graph theory and computer science, a directed acyclic graph is a directed graph with no directed cycles. That is, it consists of vertices and edges (also called arcs) with each edge directed from one vertex to another, such that following those directions will never form a closed loop. \n"
          ]
        }
      ]
    }
  ]
}